{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIWxDclvJ8Zq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix, f1_score, precision_score, recall_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrdO-1GtKTxu",
        "outputId": "f383d4dc-eb17-4eb0-b952-090fc996c65b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 255347 entries, 0 to 255346\n",
            "Data columns (total 18 columns):\n",
            " #   Column          Non-Null Count   Dtype  \n",
            "---  ------          --------------   -----  \n",
            " 0   LoanID          255347 non-null  object \n",
            " 1   Age             255347 non-null  int64  \n",
            " 2   Income          255347 non-null  int64  \n",
            " 3   LoanAmount      255347 non-null  int64  \n",
            " 4   CreditScore     255347 non-null  int64  \n",
            " 5   MonthsEmployed  255347 non-null  int64  \n",
            " 6   NumCreditLines  255347 non-null  int64  \n",
            " 7   InterestRate    255347 non-null  float64\n",
            " 8   LoanTerm        255347 non-null  int64  \n",
            " 9   DTIRatio        255347 non-null  float64\n",
            " 10  Education       255347 non-null  object \n",
            " 11  EmploymentType  255347 non-null  object \n",
            " 12  MaritalStatus   255347 non-null  object \n",
            " 13  HasMortgage     255347 non-null  object \n",
            " 14  HasDependents   255347 non-null  object \n",
            " 15  LoanPurpose     255347 non-null  object \n",
            " 16  HasCoSigner     255347 non-null  object \n",
            " 17  Default         255347 non-null  int64  \n",
            "dtypes: float64(2), int64(8), object(8)\n",
            "memory usage: 35.1+ MB\n"
          ]
        }
      ],
      "source": [
        "loan_data = pd.read_csv('/content/Loan_default.csv')\n",
        "loan_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix, f1_score, precision_score, recall_score\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "loan_data = pd.read_csv('/content/Loan_default.csv')\n",
        "\n",
        "# Label encoding for categorical columns\n",
        "categorical_columns = ['Education', 'EmploymentType', 'MaritalStatus', 'HasMortgage', 'HasDependents', 'LoanPurpose', 'HasCoSigner']\n",
        "label_encoder = LabelEncoder()\n",
        "for col in categorical_columns:\n",
        "    loan_data[col] = label_encoder.fit_transform(loan_data[col])\n",
        "\n",
        "# Drop unnecessary columns\n",
        "loan_data.drop(columns=['LoanID'], inplace=True)\n",
        "\n",
        "# Binning or Bucketing for Age\n",
        "bins = [0, 30, 50, float('inf')]\n",
        "labels = ['young', 'middle-aged', 'senior']\n",
        "loan_data['Age_Group'] = pd.cut(loan_data['Age'], bins=bins, labels=labels)\n",
        "\n",
        "# One-Hot Encoding for Age_Group\n",
        "loan_data = pd.get_dummies(loan_data, columns=['Age_Group'])\n",
        "\n",
        "# Interaction Features\n",
        "loan_data['Income_CreditScore'] = loan_data['Income'] * loan_data['CreditScore']\n",
        "loan_data['LoanAmount_InterestRate'] = loan_data['LoanAmount'] * loan_data['InterestRate']\n",
        "\n",
        "# Polynomial Features\n",
        "loan_data['Age_squared'] = loan_data['Age'] ** 2\n",
        "loan_data['Income_squared'] = loan_data['Income'] ** 2\n",
        "\n",
        "# Drop original columns used for interaction and polynomial features\n",
        "loan_data.drop(columns=['Age', 'Income', 'CreditScore', 'LoanAmount', 'InterestRate'], inplace=True)\n",
        "\n",
        "# Feature Scaling (Standard Scaling)\n",
        "scaler = StandardScaler()\n",
        "loan_data_scaled = pd.DataFrame(scaler.fit_transform(loan_data), columns=loan_data.columns)\n",
        "\n",
        "# Split data into features and target\n",
        "X = loan_data_scaled.drop(columns=['Default'])\n",
        "y = loan_data['Default']  # Assuming 'Default' is the target variable containing categorical labels (0 or 1)\n",
        "\n",
        "# Perform train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
        "\n",
        "# Define models with hyperparameters\n",
        "models = {\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=2, min_samples_leaf=1),\n",
        "    'Logistic Regression': LogisticRegression(C=1.0, max_iter=1000),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, max_depth=3, min_samples_split=2, min_samples_leaf=1),\n",
        "    'XGBoost': XGBClassifier(n_estimators=100, max_depth=3, learning_rate=0.1, gamma=0, subsample=1),\n",
        "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5)\n",
        "}\n",
        "\n",
        "# Initialize lists to store metrics\n",
        "metrics = {\n",
        "    'Model': [],\n",
        "    'Accuracy': [],\n",
        "    'F1 Score': [],\n",
        "    'Recall': [],\n",
        "    'Precision': [],\n",
        "    'AUC Score': []\n",
        "}\n",
        "\n",
        "# Train and evaluate models\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred_train = model.predict(X_train)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_train, y_pred_train)\n",
        "    f1 = f1_score(y_train, y_pred_train)\n",
        "    recall = recall_score(y_train, y_pred_train)\n",
        "    precision = precision_score(y_train, y_pred_train)\n",
        "    auc = roc_auc_score(y_train, y_pred_train)\n",
        "\n",
        "    # Store metrics\n",
        "    metrics['Model'].append(name)\n",
        "    metrics['Accuracy'].append(accuracy)\n",
        "    metrics['F1 Score'].append(f1)\n",
        "    metrics['Recall'].append(recall)\n",
        "    metrics['Precision'].append(precision)\n",
        "    metrics['AUC Score'].append(auc)\n",
        "\n",
        "# Convert metrics to DataFrame\n",
        "metrics_df = pd.DataFrame(metrics)\n",
        "\n",
        "# Set 'Model' as index\n",
        "metrics_df.set_index('Model', inplace=True)\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(metrics_df, annot=True, cmap='coolwarm', fmt=\".3f\", linewidths=0.5)\n",
        "plt.title('Training Metrics of Models')\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Model')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1IxFf9S4YECe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}